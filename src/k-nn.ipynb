{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k近邻\n",
    "图片来自《统计学习方法》。\n",
    "## 三要素\n",
    "k近邻是一个比较简单的机器学习算法，k近邻的三要素是：\n",
    "> \n",
    "- k值的选择\n",
    "- 距离度量\n",
    "- 分类决策规则\n",
    "\n",
    "给定训练集，对于新的输入，在训练集中找到与该实例最临近的k个实例，这k个实例的多数属于某一类，则认为该实例属于这个类。\n",
    "\n",
    "## 算法\n",
    "<br>\n",
    "<img src=\"https://raw.githubusercontent.com/nanyoullm/nanyoullm.github.io/master/img/k-nn%E7%AE%97%E6%B3%95.png\"  width=\"600\"/>\n",
    "<br>\n",
    "当k=1时，成为最近邻法。\n",
    "\n",
    "## k近邻模型\n",
    "### 模型\n",
    "将特征空间划分为子空间，确定空间中的每个点所属的类。\n",
    "<br>\n",
    "<img src=\"https://raw.githubusercontent.com/nanyoullm/nanyoullm.github.io/master/img/k-nn%E7%89%B9%E5%BE%81%E7%A9%BA%E9%97%B4.png\" width='400'>\n",
    "<br>\n",
    "\n",
    "### 度量距离\n",
    "$x_{i}$与$x_{j}$的距离$L_{p}$:$$L_{p}(x_{i},x_{j})=(\\sum\\limits_{l=1}^n |x_{i}^{(l)}-x_{j}^{(l)}|^{p})^\\frac{1}{p}， p>=1$$\n",
    "这个距离，又称为**范数**。  \n",
    "> \n",
    "- 当$p=1$时，成为曼哈顿距离；\n",
    "- 当$p=2$时，称为欧氏距离；\n",
    "- 当$p=\\infty$时，它是各个坐标距离的最大值；\n",
    "\n",
    "## k值的选择\n",
    "- k较小时，近似误差会减小，但估计误差会增大，结果对近邻的点敏感，如果近邻有噪声会影响很大；\n",
    "- k较大时，可以减小估计误差，增大近似误差，模型也相对更简单；\n",
    "\n",
    "## 分类决策的规则\n",
    "多数表决"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}