{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 迭代统一论\n",
    "## 无约束优化问题\n",
    "- 自变量为标量的函数: $$\\min f(x),x\\in R$$ \n",
    "<br>\n",
    "- 自变量为向量的函数：$$\\min f(x),x\\in R^{n}$$ \n",
    "<br>\n",
    "\n",
    "## 优化问题可能的极值点情况\n",
    "<br>\n",
    "<img src=\"https://github.com/nanyoullm/nanyoullm.github.io/blob/master/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%9F%B3/%E6%9E%81%E5%80%BC%E6%83%85%E5%86%B5.png?raw=true\" width=\"600\"><br>\n",
    "\n",
    "## 数学要点\n",
    "### 一阶二阶导数\n",
    "<br><img src=\"https://github.com/nanyoullm/nanyoullm.github.io/blob/master/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%9F%B3/%E4%B8%80%E9%98%B6%E4%BA%8C%E9%98%B6%E5%AF%BC%E6%95%B0.png?raw=true\" width=\"600\"><br>\n",
    "假设n维数据，x是一个向量，我们可以求得x的一阶导数，结果仍然是一个向量；对其求二阶导数，得到的是一个$n*n$的矩阵，这个矩阵被称为Hessian矩阵\n",
    "### 二次型\n",
    "<br>\n",
    "<img src=\"https://github.com/nanyoullm/nanyoullm.github.io/blob/master/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%9F%B3/%E4%BA%8C%E6%AC%A1%E5%9E%8B.png?raw=true\" width=\"600\">\n",
    "<br>\n",
    "二次型有什么用？  \n",
    "> 相对标量中的正数，二次型可以用来衡量矩阵A的“正负”  \n",
    "\n",
    "如果一个矩阵A的二次型大于等于**0**，称为半正定矩阵；大于**0**则称为正定矩阵；小于则称为负定矩阵；  \n",
    "具体计算如下：\n",
    "<br><img src=\"https://github.com/nanyoullm/nanyoullm.github.io/blob/master/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%9F%B3/%E4%BA%8C%E6%AC%A1%E5%9E%8B%E5%85%B7%E4%BD%93%E8%AE%A1%E7%AE%97.png?raw=true\" width=\"600\"><br>\n",
    "### 泰勒级数\n",
    "<br><img src=\"https://github.com/nanyoullm/nanyoullm.github.io/blob/master/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%9F%B3/%E6%B3%B0%E5%8B%92%E7%BA%A7%E6%95%B0.png?raw=true\" width=\"600\"><br>\n",
    "泰勒级数和极值求解有非常大的关联！\n",
    "\n",
    "## 无约束优化梯度分析法\n",
    "### 泰勒级数和极值\n",
    "对于标量情况下，泰勒级数和极值的关系如下\n",
    "<br><img src=\"https://github.com/nanyoullm/nanyoullm.github.io/blob/master/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%9F%B3/%E6%B3%B0%E5%8B%92%E7%BA%A7%E6%95%B0%E5%92%8C%E6%9E%81%E5%80%BC1.png?raw=true\" width=\"600\"><br>\n",
    "结合上面的知识点，在向量情况下，泰勒级数和极值的关系如下\n",
    "<br><img src=\"https://github.com/nanyoullm/nanyoullm.github.io/blob/master/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%9F%B3/%E6%B3%B0%E5%8B%92%E7%BA%A7%E6%95%B0%E5%92%8C%E6%9E%81%E5%80%BC2.png?raw=true\" width=\"600\"><br>\n",
    "## 无约束优化迭代法\n",
    "机器学习问题本质上是一个数学优化问题，我们定义了目标函数（损失函数）之后，想办法寻找损失函数的全局最小值或局部最小值，很多时候就是通过迭代求梯度、更新权值的方式寻找最优解。普遍的，无约束优化迭代法过程如下：\n",
    "<br><img src=\"https://github.com/nanyoullm/nanyoullm.github.io/blob/master/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%9F%B3/%E6%97%A0%E7%BA%A6%E6%9D%9F%E4%BC%98%E5%8C%96%E8%BF%AD%E4%BB%A3%E6%B3%95.png?raw=true\" width=\"600\"><br>\n",
    "### 梯度下降法\n",
    "<br><img src=\"https://github.com/nanyoullm/nanyoullm.github.io/blob/master/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%9F%B3/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D.png?raw=true\" width=\"600\"><br>\n",
    "### 牛顿法\n",
    "除了常见的梯度下降法，还有在数学层面上更加精准的牛顿法，牛顿法是求了目标函数的Hessian矩阵，下降方向的选取更加精准\n",
    "<br><img src=\"https://github.com/nanyoullm/nanyoullm.github.io/blob/master/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%9F%B3/%E7%89%9B%E9%A1%BF%E6%B3%95.png?raw=true\" width=\"600\"><br>\n",
    "但是牛顿法有其弱点，就是在实际的工程中，Hessian矩阵是很难解的，Hessain矩阵的逆就更难了，对此，可以用逆牛顿法来逼近牛顿法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
